{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 22:41:52.697451: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jlb638/cuda/lib64:/home/jlb638/packages/gdb/lib:/home/jlb638/packages/gcc/lib64:/home/jlb638/packages/gcc/lib:/home/jlb638/packages/gmp/5_0_2/include:/home/jlb638/packages/gmp/5_0_2/lib:/home/jlb638/texinfo/6_6/lib:/home/jlb638/gc563/python/3.9.6/lib:/home/jlb638/cuda/lib64:/home/jlb638/packages/gdb/lib:/home/jlb638/packages/gcc/lib64:/home/jlb638/packages/gcc/lib:/home/jlb638/packages/gmp/5_0_2/include:/home/jlb638/packages/gmp/5_0_2/lib:/home/jlb638/texinfo/6_6/lib:/home/jlb638/gc563/python/3.9.6/lib:\n",
      "2023-02-02 22:41:52.697572: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# keras module for building LSTM \n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "\n",
    "# set seeds for reproducability\n",
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "tf.random.set_seed(2)\n",
    "seed(1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_dijk import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 474/474 [00:00<00:00, 242kB/s]\n",
      "WARNING:datasets.builder:Using custom data configuration jlbaker361--mnist_dijkstra_v0.0-7c506d7590f9f055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/jlb638/.cache/huggingface/datasets/jlbaker361___parquet/jlbaker361--mnist_dijkstra_v0.0-7c506d7590f9f055/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 8.54M/8.54M [00:00<00:00, 43.7MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 228.12it/s]\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/jlb638/.cache/huggingface/datasets/jlbaker361___parquet/jlbaker361--mnist_dijkstra_v0.0-7c506d7590f9f055/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "big_dataset = load_dataset(\"jlbaker361/mnist_dijkstra_v0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'sequence', 'occurence', 'split'],\n",
       "        num_rows: 68533\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 22:42:28.441374: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jlb638/cuda/lib64:/home/jlb638/packages/gdb/lib:/home/jlb638/packages/gcc/lib64:/home/jlb638/packages/gcc/lib:/home/jlb638/packages/gmp/5_0_2/include:/home/jlb638/packages/gmp/5_0_2/lib:/home/jlb638/texinfo/6_6/lib:/home/jlb638/gc563/python/3.9.6/lib:/home/jlb638/cuda/lib64:/home/jlb638/packages/gdb/lib:/home/jlb638/packages/gcc/lib64:/home/jlb638/packages/gcc/lib:/home/jlb638/packages/gmp/5_0_2/include:/home/jlb638/packages/gmp/5_0_2/lib:/home/jlb638/texinfo/6_6/lib:/home/jlb638/gc563/python/3.9.6/lib:\n",
      "2023-02-02 22:42:28.441533: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-02 22:42:28.441604: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (amarel1.amarel.rutgers.edu): /proc/driver/nvidia/version does not exist\n",
      "2023-02-02 22:42:28.443275: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-02 22:42:30.048995: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-02-02 22:42:30.894549: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "small_dataset=make_dataset(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'sequence', 'occurence', 'split'],\n",
       "    num_rows: 99\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(small_dataset['sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_of_tokens(corpus):\n",
    "    all_input_sequences = []\n",
    "    all_words=set()\n",
    "    for token_list in corpus:\n",
    "        all_words.add(token_list[0])\n",
    "        all_words.add(token_list[-1])\n",
    "        for t in range(1, len(token_list)-1):\n",
    "            all_words.add(token_list[t])\n",
    "            n_gram_sequence = token_list[:t+1]\n",
    "            all_input_sequences.append(n_gram_sequence)\n",
    "\n",
    "    return all_input_sequences, len(all_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_sequences, total_words = get_sequence_of_tokens(small_dataset['sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[157, 158],\n",
       " [157, 158, 159],\n",
       " [157, 158, 159, 185],\n",
       " [157, 158, 159, 185, 186],\n",
       " [157, 158, 159, 185, 186, 187],\n",
       " [157, 158, 159, 185, 186, 187, 212],\n",
       " [157, 158, 159, 185, 186, 187, 212, 213],\n",
       " [157, 158, 159, 185, 186, 187, 212, 213, 214],\n",
       " [157, 158, 159, 185, 186, 187, 212, 213, 214, 215],\n",
       " [157, 158, 159, 185, 186, 187, 212, 213, 214, 215, 233]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_category(token,total_words): #token is number < total_words +1\n",
    "    arr=np.zeros(total_words)\n",
    "    arr[token]=1\n",
    "    return arr\n",
    "\n",
    "\n",
    "def generate_padded_sequences(input_sequences,total_words=28*28):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre', value=0))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = np.array([to_category(l,total_words) for l in label])\n",
    "    return predictors, label, max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors, label, max_sequence_len=generate_padded_sequences(inp_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0, 157],\n",
       "       [  0,   0,   0, ...,   0, 157, 158],\n",
       "       [  0,   0,   0, ..., 157, 158, 159],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 187, 212, 213],\n",
       "       [  0,   0,   0, ..., 212, 213, 214],\n",
       "       [  0,   0,   0, ..., 213, 214, 215]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 280, 10)           7840      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               44400     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 784)               79184     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131,424\n",
      "Trainable params: 131,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(max_sequence_len, total_words=28*28):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
    "    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(max_sequence_len)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15221, 280)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15221, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f01c823ba30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors, label, epochs=1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(initial_sequence, length, model, max_sequence_len):\n",
    "    current_sequence= initial_sequence\n",
    "    for _ in range(length):\n",
    "        print(current_sequence)\n",
    "        padded=np.array(pad_sequences([current_sequence], maxlen=max_sequence_len-1, padding='pre')).astype(int)\n",
    "        token=np.argmax(model(padded))\n",
    "        current_sequence.append(token)\n",
    "    return current_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 128, 101]\n",
      "[100, 128, 101, 126]\n",
      "[100, 128, 101, 126, 126]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[100, 128, 101, 126, 126, 126]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text([100,128,101], 3,model,max_sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_image(sequence,dim=28):\n",
    "    empty_c=[[0.0 for _ in range(dim)] for __ in range(dim)]\n",
    "    for token in sequence:\n",
    "        (vert,horiz)=num_to_coords(token)\n",
    "        empty_c[vert][horiz]=1\n",
    "    return empty_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f01483e4b20>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sequence_to_image([100,101,128]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e9f74c9a83faa9a28077456a45a748f5fb1d35fce40051360eebcbf390c565d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
